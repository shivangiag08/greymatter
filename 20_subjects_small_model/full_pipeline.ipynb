{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class ResNetFeatureExtractor(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ResNetFeatureExtractor, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=pretrained)\n",
    "        # Remove the final fully connected layer\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.resnet(x)\n",
    "        features = features.view(features.size(0), -1)  # Flatten\n",
    "        return features\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "    \n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        # hidden: [batch_size, hidden_size]\n",
    "        # encoder_outputs: [batch_size, seq_len, hidden_size]\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)  # [batch_size, seq_len, hidden_size]\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))  # [batch, seq, hidden]\n",
    "        energy = energy.transpose(2, 1)  # [batch, hidden, seq]\n",
    "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)  # [batch, 1, hidden]\n",
    "        energy = torch.bmm(v, energy).squeeze(1)  # [batch, seq]\n",
    "        energy = energy.masked_fill(mask == 0, -1e10)\n",
    "        return torch.softmax(energy, dim=1)  # [batch, seq]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMAttentionClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMAttentionClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.attention = Attention(hidden_size * 2)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        # x: [batch, seq_len, input_size]\n",
    "        # mask: [batch, seq_len]\n",
    "        lstm_out, _ = self.lstm(x)  # [batch, seq_len, hidden_size*2]\n",
    "        # Use the last hidden state as the query\n",
    "        hidden = lstm_out[:, -1, :]  # [batch, hidden_size*2]\n",
    "        attn_weights = self.attention(hidden, lstm_out, mask)  # [batch, seq_len]\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), lstm_out).squeeze(1)  # [batch, hidden_size*2]\n",
    "        out = self.fc(context)  # [batch, num_classes]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
