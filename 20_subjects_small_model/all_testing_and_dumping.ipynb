{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_6644\\3_Plane_Localizer\\2018-12-04_14_13_04.0\\I1083043\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\005_S_4168\\3_Plane_Localizer\\2011-08-17_13_55_20.0\\I251359\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\005_S_4168\\3_Plane_Localizer\\2012-03-28_11_44_12.0\\I294035\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\005_S_4168\\3_Plane_Localizer\\2013-09-12_13_05_35.0\\I389814\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\005_S_4168\\Axial_FLAIR\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\005_S_4168\\Axial_FLAIR\\2011-11-30_11_27_21.0\\I269263\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\005_S_4168\\Axial_FLAIR\\2015-09-14_13_55_42.0\\I511907\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\005_S_4168\\Calibration_Scan\\2012-09-06_09_46_29.0\\I331874\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\002_S_1280\\3-plane_localizer\\2007-02-13_07_57_58.0\\I40079\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\002_S_1280\\Axial_PD_T2_FSE\\2007-08-23_06_57_19.0\\I70095\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\002_S_1280\\Axial_PD_T2_FSE\\2008-03-25_10_03_26.0\\I99430\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\002_S_1280\\Axial_T2-Star\\2011-05-04_14_00_20.0\\I233443\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\002_S_1280\\Axial_T2-TSE_with_Fat_Sat\\2014-03-14_15_13_20.0\\I418028\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\002_S_1280\\Field_Mapping\\2017-03-13_13_38_31.0\\I829316\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\002_S_1280\\HighResHippocampus\\2019-03-06_09_11_05.0\\I1140416\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\002_S_6007\\Axial_3TE_T2_STAR\\2019-05-16_09_43_41.0\\I1270098\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\002_S_6007\\Field_Mapping\\2019-05-16_09_43_41.0\\I1270112\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_0908\\AXIAL_PD-T2_TSE\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_0908\\AXIAL_PD-T2_TSE\\2008-05-06_15_56_41.0\\I104924\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_0908\\AXIAL_PD-T2_TSE\\2009-10-20_08_33_24.0\\I157588\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_0908\\localizer\\2008-10-23_07_56_45.0\\I124576\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_0908\\localizer\\2010-11-09_07_11_29.0\\I298041\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_0908\\3_Plane_Localizer\\2014-01-06_13_40_49.0\\I404530\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_0908\\Axial_T2_STAR\\2019-10-29_13_33_43.0\\I1249281\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_1122\\Localizer\\2007-07-20_13_50_52.0\\I61261\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_1122\\Localizer\\2009-01-09_09_27_54.0\\I133351\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_1122\\AXIAL_PD-T2_TSE\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_1122\\AXIAL_PD-T2_TSE\\2010-01-29_07_16_28.0\\I166372\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_1122\\AXIAL_PD-T2_TSE\\2011-02-25_08_37_12.0\\I222902\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_1122\\AXIAL_PD-T2_TSE\\2012-01-20_09_34_28.0\\I281676\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_1122\\Field_Mapping\\2017-05-18_14_28_50.0\\I853510\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_1122\\3_Plane_Localizer\\2018-12-06_08_10_10.0\\I1083058\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_1122\\Axial_T2_STAR\\2019-05-07_10_25_03.0\\I1162374\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4081\\T2-weighted_trace\\2011-07-05_17_58_58.0\\I244125\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4119\\3_Plane_Localizer\\2012-02-21_12_23_55.0\\I287301\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4119\\Calibration_Scan\\2013-07-31_09_19_39.0\\I384083\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4119\\Axial_T2_Star\\2016-08-23_13_59_35.0\\I1043738\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4119\\Field_Mapping\\2019-10-29_11_00_40.0\\I1249341\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4119\\HighResHippocampus\\2021-11-09_13_02_45.0\\I1514462\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4288\\Axial_FLAIR\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4288\\Axial_FLAIR\\2012-02-14_15_04_45.0\\I287775\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4288\\3_Plane_Localizer\\2012-05-24_14_46_38.0\\I307374\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4288\\3_Plane_Localizer\\2019-09-12_13_44_02.0\\I1226296\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4288\\3_Plane_Localizer\\2021-09-30_11_15_46.0\\I1498581\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4288\\T2-weighted_trace\\2012-11-01_09_52_18.0\\I378913\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4288\\T2-weighted_trace\\2013-12-05_13_26_19.0\\I404503\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4288\\Field_Mapping\\2017-10-03_13_13_05.0\\I915009\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4288\\Field_Mapping_2.5mm\\2021-09-30_11_15_46.0\\I1498591\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4441\\Calibration_Scan\\2012-01-03_08_57_27.0\\I277114\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4441\\3_Plane_Localizer\\2012-10-18_08_53_45.0\\I341440\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4441\\3_Plane_Localizer\\2013-04-12_13_44_44.0\\I367514\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4441\\3_Plane_Localizer\\2013-04-12_13_44_44.0\\I368408\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4441\\3_Plane_Localizer\\2021-04-08_11_56_11.0\\I1430380\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4441\\Field_Mapping\\2019-04-10_12_56_15.0\\I1154575\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4644\\3_Plane_Localizer\\2012-12-18_13_17_57.0\\I356218\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4644\\3_Plane_Localizer\\2013-05-24_11_48_06.0\\I492721\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4644\\Field_Mapping\\2017-06-21_15_28_29.0\\I863261\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4644\\Field_Mapping\\2021-07-29_12_57_24.0\\I1477578\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4644\\HighResHippocampus\\2019-06-21_13_23_09.0\\I1178913\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4872\\T2-weighted_trace\\2012-10-16_11_44_35.0\\I341337\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4872\\3_Plane_Localizer\\2013-04-18_09_21_47.0\\I368364\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4872\\Calibration_Scan\\2013-08-30_10_13_18.0\\I389911\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4872\\Field_Mapping\\2022-07-21_11_13_34.0\\I1607806\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4900\\3_Plane_Localizer\\2012-08-15_18_07_04.0\\I325730\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4900\\3_Plane_Localizer\\2012-11-02_13_24_39.0\\I379025\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4900\\Axial_T2_Star\\2013-02-14_15_19_35.0\\I367534\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4900\\Axial_T2_Star\\2013-08-16_15_13_52.0\\I389885\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_4900\\Field_Mapping\\2019-11-08_13_01_36.0\\I1255156\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_5154\\Axial_T2_Star\\2013-04-30_15_39_31.0\\I371606\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_5154\\Axial_T2_Star\\2022-06-09_13_39_07.0\\I1589389\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_5154\\Field_Mapping\\2018-05-02_16_06_42.0\\I992576\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_6014\\Field_Mapping\\2018-02-15_10_23_05.0\\I965020\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_6014\\3_Plane_Localizer\\2022-04-04_13_16_41.0\\I1564164\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_6067\\3_Plane_Localizer\\2019-10-01_13_11_34.0\\I1235544\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_6067\\HighResHippocampus\\2021-10-27_10_08_28.0\\I1511207\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_6256\\3_Plane_Localizer\\2018-03-13_15_53_35.0\\I973289\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_6256\\3_Plane_Localizer\\2022-05-19_13_18_40.0\\I1582531\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_6258\\3_Plane_Localizer\\2018-03-13_13_08_40.0\\I973304\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_6258\\3_Plane_Localizer\\2021-04-06_13_54_53.0\\I1429987\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_6258\\Field_Mapping\\2019-05-02_11_25_07.0\\I1161007\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_6259\\Axial_T2_STAR\\2018-03-23_16_20_17.0\\I977356\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_6259\\Field_Mapping\\2022-05-10_13_24_47.0\\I1578916\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_6268\\Field_Mapping\\2018-06-05_13_26_43.0\\I1005894\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_6268\\3_Plane_Localizer\\2019-08-06_13_16_23.0\\I1196224\n",
      "    Processing directory: D:/DL_DATASET/test_folder/ADNI\\003_S_6268\\3_Plane_Localizer\\2021-08-24_09_32_39.0\\I1494016\n",
      "Metadata saved to 'dicom_metadata.csv'\n",
      "  patient_id scan_type            datetime  \\\n",
      "0      003_S      6644 2018-12-06 18:58:32   \n",
      "1      005_S      4168 2011-08-17 16:28:48   \n",
      "2      005_S      4168 2011-08-17 16:28:48   \n",
      "3      005_S      4168 2011-08-17 16:28:48   \n",
      "4      005_S      4168 2012-03-28 12:58:15   \n",
      "\n",
      "                                            filename  \\\n",
      "0  ADNI_003_S_6644_MR_3_Plane_Localizer__raw_2018...   \n",
      "1  ADNI_005_S_4168_MR_3_Plane_Localizer__br_raw_2...   \n",
      "2  ADNI_005_S_4168_MR_3_Plane_Localizer__br_raw_2...   \n",
      "3  ADNI_005_S_4168_MR_3_Plane_Localizer__br_raw_2...   \n",
      "4  ADNI_005_S_4168_MR_3_Plane_Localizer__br_raw_2...   \n",
      "\n",
      "                                           file_path  \n",
      "0  D:/DL_DATASET/test_folder/ADNI\\003_S_6644\\3_Pl...  \n",
      "1  D:/DL_DATASET/test_folder/ADNI\\005_S_4168\\3_Pl...  \n",
      "2  D:/DL_DATASET/test_folder/ADNI\\005_S_4168\\3_Pl...  \n",
      "3  D:/DL_DATASET/test_folder/ADNI\\005_S_4168\\3_Pl...  \n",
      "4  D:/DL_DATASET/test_folder/ADNI\\005_S_4168\\3_Pl...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def parse_dicom_filename(file_name):\n",
    "    # Regex to extract datetime in format YYYYMMDDHHMMSS\n",
    "    datetime_pattern = r\"(\\d{8})(\\d{6})\"  # Matches YYYYMMDDHHMMSS\n",
    "\n",
    "    # Split the filename by underscores ('_')\n",
    "    parts = file_name.split('_')\n",
    "\n",
    "    # Extract patient ID\n",
    "    patient_id = parts[1] + \"_\" + parts[2]  # e.g., 003_S_6644\n",
    "\n",
    "    # Extract scan type\n",
    "    scan_type = parts[3] if len(parts) >= 4 else None\n",
    "\n",
    "    # Use regex to find the datetime in the filename\n",
    "    match = re.search(datetime_pattern, file_name)\n",
    "    if match:\n",
    "        date_part = match.group(1)  # YYYYMMDD\n",
    "        time_part = match.group(2)  # HHMMSS\n",
    "        datetime_str = f\"{date_part[:4]}-{date_part[4:6]}-{date_part[6:8]} {time_part[:2]}:{time_part[2:4]}:{time_part[4:6]}\"\n",
    "        try:\n",
    "            datetime_obj = datetime.strptime(datetime_str, '%Y-%m-%d %H:%M:%S')\n",
    "        except ValueError:\n",
    "            datetime_obj = None\n",
    "    else:\n",
    "        datetime_obj = None\n",
    "\n",
    "    return {\n",
    "        'patient_id': patient_id,\n",
    "        'scan_type': scan_type,\n",
    "        'datetime': datetime_obj,\n",
    "        'filename': file_name\n",
    "    }\n",
    "\n",
    "def process_folders(base_dir):\n",
    "    # List to store parsed data\n",
    "    all_data = []\n",
    "\n",
    "    # Traverse directories with os.walk()\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        if 'I' in os.path.basename(root):  # Only look at folders containing DICOM files\n",
    "            # print(f'    Processing directory: {root}')\n",
    "            \n",
    "            # Loop through files and try parsing the DICOM filenames\n",
    "            for file_name in files:\n",
    "                if file_name.endswith('.dcm'):\n",
    "                    file_path = os.path.join(root, file_name)\n",
    "                    \n",
    "                    # Parse the filename and append to the data list\n",
    "                    parsed_data = parse_dicom_filename(file_name)\n",
    "                    if parsed_data:\n",
    "                        parsed_data['file_path'] = file_path  # Add full file path to the data\n",
    "                        all_data.append(parsed_data)\n",
    "\n",
    "    # Convert the data into a DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    # Save the DataFrame to a CSV file for further analysis\n",
    "    df.to_csv(\"dicom_metadata.csv\", index=False)\n",
    "    print(\"Metadata saved to 'dicom_metadata.csv'\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Set the base directory\n",
    "base_dir = \"D:/DL_DATASET/test_folder/ADNI\"  # Adjust this to your actual directory\n",
    "\n",
    "# Process the directories and get the DataFrame\n",
    "df = process_folders(base_dir)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to merged_mri_metadata.csv\n",
      "                                          dicom_file  patient_id    mri_date  \\\n",
      "0  ADNI_003_S_6644_MR_3_Plane_Localizer__raw_2018...  003_S_6644  2018-12-04   \n",
      "1  ADNI_005_S_4168_MR_3_Plane_Localizer__br_raw_2...  005_S_4168  2011-08-17   \n",
      "2  ADNI_005_S_4168_MR_3_Plane_Localizer__br_raw_2...  005_S_4168  2011-08-17   \n",
      "3  ADNI_005_S_4168_MR_3_Plane_Localizer__br_raw_2...  005_S_4168  2011-08-17   \n",
      "4  ADNI_005_S_4168_MR_3_Plane_Localizer__br_raw_2...  005_S_4168  2012-03-28   \n",
      "\n",
      "  mri_acq_plane    mri_description mri_type mri_sequence  mri_field_str  \n",
      "0      SAGITTAL  3 Plane Localizer       2D           GR            3.0  \n",
      "1      SAGITTAL  3 Plane Localizer       2D           GR            3.0  \n",
      "2      SAGITTAL  3 Plane Localizer       2D           GR            3.0  \n",
      "3      SAGITTAL  3 Plane Localizer       2D           GR            3.0  \n",
      "4       CORONAL  3 Plane Localizer       2D           GR            3.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load metadata CSV into pandas dataframe (the provided dataset)\n",
    "metadata_df = pd.read_csv(\"D:/DL_DATASET/Cohort_4_MRI_Images_02Dec2024.csv\")\n",
    "\n",
    "# Load the dicom_metadata CSV (already extracted from filenames)\n",
    "dicom_metadata_path = \"dicom_metadata.csv\"\n",
    "dicom_metadata_df = pd.read_csv(dicom_metadata_path)\n",
    "\n",
    "# List to hold the matched results\n",
    "matches = []\n",
    "\n",
    "# Iterate over all DICOM files in the dicom_metadata.csv\n",
    "for index, dicom_row in dicom_metadata_df.iterrows():\n",
    "    # Extract image_id from the dicom file\n",
    "    dicom_file = dicom_row['filename']\n",
    "    image_id = dicom_file.split(\"I\")[-1].split(\".\")[0]\n",
    "    \n",
    "    # Match the image_id with metadata\n",
    "    metadata_row = metadata_df[metadata_df['image_id'] == int(image_id)]\n",
    "    \n",
    "    if not metadata_row.empty:\n",
    "        # Extract relevant details\n",
    "        patient_id = metadata_row['subject_id'].values[0]\n",
    "        mri_date = metadata_row['mri_date'].values[0]\n",
    "        mri_acq_plane = metadata_row['mri_acq_plane'].values[0]\n",
    "        mri_description = metadata_row['mri_description'].values[0]\n",
    "        mri_type = metadata_row['mri_type'].values[0]\n",
    "        mri_sequence = metadata_row['mri_sequence'].values[0]\n",
    "        mri_field_str = metadata_row['mri_field_str'].values[0]\n",
    "        \n",
    "        # Add matched data to the list\n",
    "        matches.append({\n",
    "            'dicom_file': dicom_file,\n",
    "            'patient_id': patient_id,\n",
    "            'mri_date': mri_date,\n",
    "            'mri_acq_plane': mri_acq_plane,\n",
    "            'mri_description': mri_description,\n",
    "            'mri_type': mri_type,\n",
    "            'mri_sequence': mri_sequence,\n",
    "            'mri_field_str': mri_field_str\n",
    "        })\n",
    "    else:\n",
    "        print(f\"No metadata found for {dicom_file}\")\n",
    "\n",
    "# Convert matches to a DataFrame and save to CSV\n",
    "matched_df = pd.DataFrame(matches)\n",
    "\n",
    "# Specify the path for the merged file\n",
    "merged_metadata_path = \"merged_mri_metadata.csv\"\n",
    "\n",
    "# Save the matched data\n",
    "matched_df.to_csv(merged_metadata_path, index=False)\n",
    "\n",
    "# Show a preview of the merged data\n",
    "print(f\"Merged data saved to {merged_metadata_path}\")\n",
    "print(matched_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2503/2503 [00:30<00:00, 80.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Images saved as .npy.\n"
     ]
    }
   ],
   "source": [
    "import pydicom\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the merged metadata file\n",
    "metadata_df = pd.read_csv('dicom_metadata.csv')\n",
    "\n",
    "# Function to load DICOM images and preprocess them\n",
    "def load_and_preprocess_dicom(file_path, target_size=(256, 256)):\n",
    "    # Read DICOM file\n",
    "    dicom_data = pydicom.dcmread(file_path)\n",
    "    \n",
    "    # Convert DICOM pixel data to numpy array (assuming the pixel data is in the 'PixelData' attribute)\n",
    "    img = dicom_data.pixel_array\n",
    "    \n",
    "    # Resize the image by padding if necessary to maintain the aspect ratio\n",
    "    h, w = img.shape\n",
    "    scale = min(target_size[0] / h, target_size[1] / w)\n",
    "    new_w = int(w * scale)\n",
    "    new_h = int(h * scale)\n",
    "    \n",
    "    # Resize the image to the new dimensions\n",
    "    resized_img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # Add padding to make it the target size\n",
    "    top = (target_size[0] - new_h) // 2\n",
    "    bottom = target_size[0] - new_h - top\n",
    "    left = (target_size[1] - new_w) // 2\n",
    "    right = target_size[1] - new_w - left\n",
    "    \n",
    "    padded_img = cv2.copyMakeBorder(resized_img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n",
    "    \n",
    "    return padded_img\n",
    "\n",
    "# Prepare the data\n",
    "processed_images = []\n",
    "\n",
    "# Loop through the metadata and process each file\n",
    "for idx, row in tqdm(metadata_df.iterrows(), total=metadata_df.shape[0]):\n",
    "    dicom_file = row['file_path']\n",
    "    \n",
    "    # Check if the file exists (ensure you have valid paths)\n",
    "    try:\n",
    "        processed_img = load_and_preprocess_dicom(dicom_file)\n",
    "        processed_images.append(processed_img)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {dicom_file}: {e}\")\n",
    "\n",
    "# Convert list of images into numpy array\n",
    "processed_images_array = np.array(processed_images)\n",
    "\n",
    "# Save the preprocessed images as .npy file\n",
    "np.save(\"D:/DL_DATASET/processed_images.npy\", processed_images_array)\n",
    "\n",
    "print(\"Preprocessing complete. Images saved as .npy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Select 10 random indices from the processed images to visualize\n",
    "indices = np.random.choice(len(processed_images_array), 5, replace=False)\n",
    "\n",
    "# Plot the original vs processed images\n",
    "fig, axes = plt.subplots(5, 2, figsize=(10, 30))\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    # Load original DICOM image\n",
    "    dicom_file = metadata_df.iloc[idx]['file_path']\n",
    "    dicom_data = pydicom.dcmread(dicom_file)\n",
    "    original_img = dicom_data.pixel_array\n",
    "    \n",
    "    # Get the processed image\n",
    "    processed_img = processed_images_array[idx]\n",
    "    \n",
    "    # Plot original image\n",
    "    axes[i, 0].imshow(original_img, cmap='gray')\n",
    "    axes[i, 0].set_title(f\"Original Image {idx+1}\")\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Plot processed image\n",
    "    axes[i, 1].imshow(processed_img, cmap='gray')\n",
    "    axes[i, 1].set_title(f\"Processed Image {idx+1}\")\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tf-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
